export  const MenuData =  {
    "Data Management": {
      "Column Operations": [
        "Delete Column(s)",
        "Rename Column (s)",
        "Sort",
        "Sort on Multiple Columns"
      ],
      "Data Sampling/Subsetting": [
        "Filter Categorical",
        "Filter Numeric",
        "One Stage Cluster Sample",
        "Random Sample",
        "Split Data (Py)",
        "Stratified Split (Py)",
        "Subset",
        "Systematic Sample"
      ],
      "Date-Time Functions": [
        "Check Date Column(s)",
        "Date Difference",
        "Day",
        "Elapsed Time",
        "Format Date Column",
        "Month",
        "Weekday",
        "Year"
      ],
      "Row Operations": ["Alias", "Alias By Number", "If", "If Numeric"],
      "String Operations": [
        "Append String",
        "Concatenate",
        "Evaluate String Expression",
        "Extract String",
        "Extract String From Left",
        "Extract String From Right",
        "Lower Case",
        "String Distance",
        "String Length",
        "String Padding",
        "Trim",
        "Upper Case"
      ],
      "Table Operations": [
        "Append Tables",
        "Full Outer Join",
        "Inner Join",
        "Left Outer Join",
        "Right Outer Join",
        "Transpose"
      ]
    },
    "Data Mining": {
      "Data Cleansing": [
        "Remove Duplicates",
        "Remove Inf",
        "Remove Missings",
        "Remove NaN"
      ],
      "Data Profiling": [
        "Check Duplicates",
        "Check Missing",
        "Check Outliers",
        "Count Infinity",
        "Count NA",
        "Count NaN",
        "Describe Data",
        "Summarise Data"
      ],
      "Data Standardization": [
        "Normalize by Max Min",
        "Normalize By Maximum",
        "Normalize by Mean",
        "Normalize By Minimum"
      ],
      "Missing Value Treatment": [
        "Treat Missing By",
        "Treat Missing by Constant",
        "Treat Missing By Log Odds Ratio",
        "Treat Missing By Predictive Imputation",
        "Treat Missing by trimmed Mean",
        "Treat Missing Replace Constant Catagorical"
      ],
      "Outlier Treatment": ["Treat Outliers by Floor-Cap"]
    },
    "Data Visualization": {
      "Advanced Charts": [
        "Auto-correlation Plot",
        "Bubble Chart (IN)",
        "Bubble Plot (Py)",
        "Circle Packing",
        "Correlation Plot",
        "Correlation Plot (Py)",
        "Radar Plot",
        "Radar Plot (Py)",
        "Venn Diagram"
      ],
      "Distribution Charts": [
        "Box Plot",
        "Box Plot (Py)",
        "Density Plot",
        "Density Plot (Py)",
        "Density Plot By Group",
        "Density Plot By Group (Py)",
        "Histogram",
        "Histogram Plot (Py)",
        "Quantile-Quantile Plot",
        "Quantile-Quantile Plot (Py)"
      ],
      "Bar Charts": [
        "Bar Chart (IN)",
        "Bar Plot With Error Bars",
        "BarLine Chart (IN)",
        "Grouped Bar Chart",
        "Grouped Bar Chart (IN)",
        "Horizontal Bar Chart",
        "Stacked Bar Chart",
        "Stacked Bar Chart (IN)",
        "Vertical Bar Chart"
      ],
      "Line Charts": [
        "Dot Chart",
        "Line Chart",
        "Line Chart (IN)",
        "Multi-Series Line Chart (IN)"
      ],
      Maps: ["USA States Map (IN)", "World Map (IN)"],
      "Pie Charts": [
        "Doughnut Chart",
        "Pie Chart",
        "Pie Chart (IN)",
        "Pie Chart 3D",
        "Tree Map"
      ],
      "Scatter Plots": [
        "Contour Plot (2D)",
        "Scatter Plot",
        "Scatter Plot (IN)",
        "Scatter Plot (Py)",
        "Scatter Plot 3D",
        "Scatter Plot 3D (Py)",
        "Scatter Plot By Group",
        "Scatter Plot By Group (Py)",
        "Scatter Plot Fit Line",
        "Scatter Plot Fit Line (Py)",
        "Scatter Plot Matrix",
        "Scatter Plot Matrix (Py)"
      ]
    },
    "Math & Stats": {
      "Arithmetic Operations": [
        "Absolute",
        "Add Constant",
        "Binary To Decimal",
        "Binary To Octal",
        "Cube",
        "Cube Root",
        "Cumulative Sum",
        "Decimal to Binary",
        "Decimal To Hexadecimal",
        "Difference of Two Columns",
        "Divide by Constant",
        "Exponential",
        "Floor",
        "HextoDec",
        "Logarithm",
        "Multiply by Constant",
        "Percentage Difference",
        "Power",
        "Product of Columns",
        "Proportion",
        "Ratio of Two Columns",
        "Reciprocal",
        "Round Decimals",
        "Square",
        "Square Root",
        "Subtract by Constant",
        "Sum",
        "Sum of Columns"
      ],
      "Descriptive Statistics": [
        "Average of Columns",
        "Coefficient of Variation",
        "Correlation",
        "Covariance",
        "Inter Quartile Range",
        "Kurtosis",
        "Maximum",
        "Mean",
        "Median",
        "Minimum",
        "Mode",
        "Percentile",
        "Quartile",
        "Skewness",
        "Standard Deviation",
        "Summary",
        "Trimmed Mean",
        "Variance"
      ],
      "Design of Experiments": [
        "Central Composite Design",
        "Fractional Factorial Design",
        "Latin Square",
        "Loss Function",
        "Plackett-Burman",
        "Taguchi Design"
      ],
      "Data Aggregation": [
        "Cross-Tabulation",
        "Frequency",
        "Pivot (IN)",
        "Pivot Table",
        "Query Data",
        "Rank",
        "Relative Frequency",
        "Roll Up",
        "SQL"
      ],
      "Derived Variables": [
        "Bucket by Custom Inputs",
        "Bucket by Rank",
        "Bucket by Value",
        "Discretize",
        "Dummy Variable",
        "Evaluate an expression",
        "Evaluate an expression on One Column",
        "Random Number Generation",
        "Two-Entity Percent Difference by Class"
      ],
      "Logical Operations": ["AND", "NAND", "NOR", "NOT", "OR", "XNOR", "XOR"],
      "Hypothesis Testing": [
        "Chi-Squared Independence Test",
        "Correlation Test",
        "F Test - Paired Sample",
        "F Test - Two Sample",
        "One Variable Z Test",
        "One-Variable t-Test",
        "Paired t-Test",
        "Shapiro Wilk Normality Test",
        "Two Sample t-Test",
        "Two-Sample Kolmogorov-Smirnov Test"
      ],
      "Statistical Distributions": [
        "Binomial Distribution",
        "Gamma Distribution",
        "Poisson Distribution"
      ],
      Optimization: [
        "Assignment Problem",
        "Euclidean Distance",
        "Integer Programming",
        "Knapsack Problem",
        "Linear Fractional Programming",
        "Linear Programming",
        "Minimum Spanning Tree",
        "Shortest Path Problem",
        "Transportation Problem",
        "Transshipment Problem",
        "Traveling Salesman Problem"
      ]
    },
    "Machine Learning": {
      "Regression Models": [
        "Bayesian Logistic Regression ",
        "Bootstrap Logistic Regression",
        "Generalized Linear Regression",
        "Generalized Linear Regression (Py)",
        "Generate Logistic Fit Model",
        "Hidden Markov Model",
        "Linear Regression",
        "Linear Regression Numeric Data (Py)",
        "Logistic Regression",
        "Logistic Regression Numeric Data (Py)",
        "PLS Classifier",
        "Predict from Logistic Fit Model",
        "Random Forest Regression",
        "Random Forest Regression Numeric Data (Py)",
        "RBF Network",
        "SMO Regression",
        "SVM Regression"
      ],
      "Regression Analysis (Linear)": [
        "Analysis Of Variance",
        "Backward Elimination",
        "Breausch-Pagan Test",
        "Calculate Estimated Score",
        "Coefficient of Determination (R-Squared)",
        "Durbin-Watson Test",
        "Fisher's LSD",
        "Forward Selection",
        "Least Squares Method",
        "Step-wise Regression",
        "Tukey HSD"
      ],
      "Regression Analysis (Non-Linear)": [
        "Akaike Information Criterion (AIC)",
        "Bayesian Information Criterion (BIC)",
        "Calculate-Probability Score",
        "Concordance Check",
        "Hosmer-Lemeshow Goodness-of-Fit Test",
        "Kolmogorov-Smirnov Diagnostics",
        "Likelihood-Ratio Test",
        "Log-Likelihood",
        "Log-Odds Ratio",
        "Logistic Probability Score",
        "Logit Plot",
        "Odds Ratio",
        "Score Test",
        "Validate-Logisitic Regression",
        "Wald Test"
      ],
      Filtering: [
        "Chi-Squared",
        "Condition Index",
        "Consistency-based Subset Eval",
        "Correlation-based Feature Selection",
        "EM Imputation",
        "Gain Ratio",
        "Gini Index",
        "Greedy Stepwise",
        "Information Gain",
        "Information Value",
        "Kernel Filter",
        "Linear Forward Selection",
        "LOF",
        "Multi-Collinearity Check",
        "Principal Component Analysis",
        "Variable Clustering",
        "Variance Inflation Factors (VIF)",
        "Weight of Evidence"
      ],
      "Survival Analysis": ["Cox-PH Survival Model", "Survival Probability"],
      RFMAnalysis: ["RFMAnalysis"],
      "Association Mining": [
        "Apriori Algorithm",
        "Convert To Transaction List",
        "Frequent Item Set"
      ],
      "Classification (Tree Based)": [
        "Ada Boost Algorithm",
        "Decision Tree CART",
        "Decision Tree CART (Py)",
        "Decision Tree CART (Tree Plot)",
        "DecisionTree CHAID",
        "DecisionTrees C5.0",
        "Gradient Boosting Classification",
        "Gradient Boosting Classifier Numeric (Py)",
        "K Nearest Neighbor Numeric Classifier (Py)",
        "Random Forest Classification Numerical (Py)",
        "Random Forest Classifier (Numeric Data)"
      ],
      "Classification (Others)": [
        "Artificial Neural Network Numeric Classifier (Py)",
        "Bayesian Network Classifier",
        "Conditional Probability",
        "Cost-Sensitive Classifier",
        "k-Nearest Neighbour Classifier",
        "Naive Bayes Classifier",
        "Neural Network Classifier",
        "Prior Probability",
        "SVM Classifier (Numeric Data)"
      ],
      Clustering: [
        "Density Clustering",
        "EM Clustering",
        "Farthest First Clustering",
        "GAA Clustering",
        "Hierarchical Clustering",
        "K Means Clustering Numeric (Py)",
        "k-Means Clustering (Numeric Data)",
        "k-Medoids Clustering (Numeric Data)",
        "Optimal Number of Clusters",
        "Random Forest Clustering (Numeric Data)"
      ]
    },
    "Time Series Analysis": {
      "Managing Time Series Data": [
        "Build Time Series Object From Data",
        "Cycle By Time",
        "Data Summary",
        "Delta Time",
        "Smoothing Data",
        "Time Series Plot",
        "View Data",
        "Window"
      ],
      "Exploring Time Series Data": [
        "Auto-Correlation Function (ACF)",
        "Cross-Correlation Function (CCF)",
        "Detrend Data",
        "Generalized Filter",
        "Linear Filtering",
        "Partial Auto-Correlation Function (PACF)"
      ],
      "Time Series Modeling": [
        "ARIMA Model (ARIMA(p;d;q))",
        "ARMA Model (ARMA(p;q))",
        "Auto-Regressive Model (AR(p))",
        "Automatic ARIMA Model (ARIMA(p;d;q))",
        "GARCH Model",
        "Holt-Winters Model",
        "Moving Average Model (MA(q))",
        "Seasonal ARIMA Model (ARIMA(p;d;q))",
        "Vector Auto-Regressive Model (VAR(p))"
      ],
      "Testing Time Series Data": [
        "ADF Test",
        "Box Test",
        "CoIntegration Test",
        "JarqueBeraTest",
        "KPSS Test",
        "Mann-Kendall Test",
        "Nonlinearity Test",
        "Normality Test",
        "Randomness Test",
        "Stationarity Test"
      ]
    },
    "Text Analytics": {
      "Build Corpus": ["Build Corpus"],
      "Information Retrieval": [
        "Decision Tree Classifier Text Data (Py)",
        "Dissimilarity Between Two Documents",
        "Distance Measure",
        "Distance Measure (Py)",
        "Find Associations",
        "Frequent Terms",
        "Frequent Terms (Py)",
        "N-grams Generator",
        "Ngrams Generator (Py)",
        "Parts-Of-Speech Tagger",
        "Parts-Of-Speech Tagger(Py)",
        "Sentence Tokenizer",
        "Sentence Tokenizer (Py)",
        "Text Chunking",
        "TFIDF Metric",
        "TFIDF Metric (Py)",
        "Tokenize",
        "Tokenizer (Py)",
        "Word Cloud",
        "Word Cloud (Comparison Cloud)",
        "Word Cloud (Py)",
        "Word Cloud by Class",
        "Word Cloud by Class (Py)",
        "Word Comparison Plot (Bar Chart)",
        "Word Tokenizer",
        "Word Tokenizer (Py)"
      ],
      "Insights Extraction": ["Sentiment Analysis", "Sentiment Analysis (Py)"],
      "Text Classification": [
        "Decision Trees Classifier (Text Data)",
        "Naive Bayes Classification Text Data (Py)",
        "Naive Bayes Classifier(Text Data)",
        "Random Forest Classification (Py)",
        "Random Forest Classifier (Text Data)",
        "SLDA Classification Text Data (Py)",
        "SLDA Classifier Model",
        "SVM Classification Text Data (Py)",
        "SVM Classifier (Text Data)"
      ],
      "Text Clustering": [
        "K Means Clustering Text Data (Py)",
        "k-Means Clustering (Text Data)",
        "k-Medoids Clustering (Text Data)",
        "Random Forest Clustering (Text Data)"
      ],
      "Text Pre-processing": [
        "Remove Numbers",
        "Remove Numbers (Py)",
        "Remove Punctuation (Py)",
        "Remove Punctuations",
        "Remove URL",
        "Remove URL (Py)",
        "Remove Words",
        "Remove Words (Py)",
        "Replace Abbreviations",
        "Replace Contractions",
        "Replace Numbers",
        "Replace Symbols",
        "Stem Document",
        "Stem Document (Py)",
        "Term Document (Py)",
        "Term-Document CSV",
        "To Lower Case",
        "To Lower Case (Py)",
        "To Upper Case",
        "To Upper Case (Py)"
      ]
    }
  };